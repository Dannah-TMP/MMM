{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dannah-TMP/MMM/blob/main/demo/Meridian_RF_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuQtvbG_vILv"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/meridian/blob/main/demo/Meridian_RF_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/meridian/blob/main/demo/Meridian_RF_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqSiFABximWU"
      },
      "source": [
        "# **Meridian Reach and Frequency Demo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckR-pavwis-Q"
      },
      "source": [
        "Welcome to the Meridian end-to-end demo for Reach and Frequency data. This simplified demo showcases the fundamental functionalities and basic usage of the library on data containing Reach and Frequency channels, including working examples of the major modeling steps:\n",
        "\n",
        "\n",
        "<ol start=\"0\">\n",
        "  <li><a href=\"#install\">Install</a></li>\n",
        "  <li><a href=\"#load-data\">Load the data</a></li>\n",
        "  <li><a href=\"#configure-model\">Configure the model</a></li>\n",
        "  <li><a href=\"#model-diagnostics\">Run model diagnostics</a></li>\n",
        "  <li><a href=\"#generate-summary\">Generate model results & two-page output</a></li>\n",
        "  <li><a href=\"#generate-optimize\">Run budget optimization & two-page output</a></li>\n",
        "  <li><a href=\"#save-model\">Save the model object</a></li>\n",
        "</ol>\n",
        "\n",
        "\n",
        "Note that this notebook skips all of the exploratory data analysis and preprocessing steps. It assumes that you have completed these tasks before reaching this point in the demo.\n",
        "\n",
        "This notebook utilizes sample data. As a result, the numbers and results obtained might not accurately reflect what you encounter when working with a real dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GicRPam0mUhF"
      },
      "source": [
        "<a name=\"install\"></a>\n",
        "## Step 0: Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDdX9WofM2fx"
      },
      "source": [
        "1\\. Make sure you are using one of the available GPU Colab runtimes which is **required** to run Meridian. You can change your notebook's runtime in `Runtime > Change runtime type` in the menu. All users can use the T4 GPU runtime which is sufficient to run the demo colab, free of charge. Users who have purchased one of Colab's paid plans have access to premium GPUs (such as V100, A100 or L4 Nvidia GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFYRTDuesa1P"
      },
      "source": [
        "2\\. Install the latest version of Meridian, and verify that GPU is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1jAk386jF3k"
      },
      "outputs": [],
      "source": [
        "# Install meridian: from PyPI @ latest release\n",
        "!pip install --upgrade google-meridian[colab,and-cuda]\n",
        "\n",
        "# Install meridian: from PyPI @ specific version\n",
        "# !pip install google-meridian[colab,and-cuda]==1.0.3\n",
        "\n",
        "# Install meridian: from GitHub @HEAD\n",
        "# !pip install --upgrade \"google-meridian[colab,and-cuda] @ git+https://github.com/google/meridian.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fhwt1wzgLwpZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import arviz as az\n",
        "\n",
        "import IPython\n",
        "\n",
        "from meridian import constants\n",
        "from meridian.data import load\n",
        "from meridian.data import test_utils\n",
        "from meridian.model import model\n",
        "from meridian.model import spec\n",
        "from meridian.model import prior_distribution\n",
        "from meridian.analysis import optimizer\n",
        "from meridian.analysis import analyzer\n",
        "from meridian.analysis import visualizer\n",
        "from meridian.analysis import summarizer\n",
        "from meridian.analysis import formatter\n",
        "\n",
        "# check if GPU is available\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiM0UrN6qbIP"
      },
      "source": [
        "<a name=\"load-data\"></a>\n",
        "## Step 1: Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z18Mo-22x0lY"
      },
      "source": [
        "Load the [simulated dataset in CSV format](https://github.com/google/meridian/blob/main/meridian/data/simulated_data/csv/geo_media_rf.csv) as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZd-ik8NbjK6"
      },
      "source": [
        "1\\. Map the column names to their corresponding variable types. For example, the column names 'GQV' and 'Competitor_Sales' are mapped to `controls`. The required variable types are `time`, `controls`, `population`, `kpi`, `revenue_per_kpi`, `media` and `spend`. If your data includes organic media or non-media treatments, you can add them using `organic_media` and `non_media_treatments` arguments. For the definition of each variable, see\n",
        "[Collect and organize your data](https://developers.google.com/meridian/docs/user-guide/collect-data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sV1ChiEYuyD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import the library to mount Google Drive\n",
        "from google.colab import drive\n",
        "# Mount the Google Drive at /content/drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kbHkSEIkbQQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Import the library to mount Google Drive\n",
        "# Mount the Google Drive at /content/drive'\n",
        "# This line might already be executed above, but keep it for self-containment\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 1. Load the CSV file\n",
        "file_path = \"/content/drive/MyDrive/MMM_Meridian.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 2. Clean column names (remove spaces and dots)\n",
        "df.columns = df.columns.str.strip()                      # Remove extra spaces\n",
        "df.columns = df.columns.str.replace('.', '', regex=False)  # Remove periods\n",
        "df.columns = df.columns.str.replace(' ', '_')            # Replace spaces with underscores\n",
        "\n",
        "# 3. Clean and convert numeric columns\n",
        "df['Impression'] = df['Impression'].astype(str).str.replace(',', '')   # Remove commas from 'Impr'\n",
        "df['Impression'] = pd.to_numeric(df['Impression'], errors='coerce')    # Convert 'Impr' to numeric\n",
        "df['Conversions'] = pd.to_numeric(df['Conversions'], errors='coerce')\n",
        "df['Cost'] = pd.to_numeric(df['Cost'], errors='coerce')\n",
        "df['Week_(Mon_to_Sun)'] = pd.to_datetime(df['Week_(Mon_to_Sun)'], format='%d/%m/%Y', errors='coerce')\n",
        "# Keep the datetime format for now to ensure consistent weekly intervals\n",
        "# df['Week_(Mon_to_Sun)'] = df['Week_(Mon_to_Sun)'].dt.strftime('%Y-%m-%d') # Convert later if needed\n",
        "\n",
        "df[\"Campaign_type\"] = df[\"Campaign_type\"].replace('Performance_Max', 'PMAX', regex=True)\n",
        "df[\"Campaign_type\"] = df[\"Campaign_type\"].replace('Demand_Gen', 'DemandGen', regex=True)\n",
        "\n",
        "print(df[\"Campaign_type\"].unique())\n",
        "\n",
        "# Add cleaning for GQV and Impression_share here\n",
        "# Assuming GQV might have commas or non-numeric characters\n",
        "if 'GQV' in df.columns:\n",
        "    df['GQV'] = df['GQV'].astype(str).str.replace(',', '', regex=False)\n",
        "    df['GQV'] = pd.to_numeric(df['GQV'], errors='coerce') # Use coerce to turn errors into NaN\n",
        "\n",
        "# Assuming Impression_share might be percentages like '10%'\n",
        "if 'Impression_share' in df.columns:\n",
        "    df['Impression_share'] = df['Impression_share'].astype(str).str.replace('%', '', regex=False)\n",
        "    df['Impression_share'] = pd.to_numeric(df['Impression_share'], errors='coerce') # Use coerce\n",
        "\n",
        "# 4. Create a new column for Conversion Rate\n",
        "# Note: This Conversion Rate is campaign-specific based on the original data structure\n",
        "# Avoid division by zero\n",
        "df['Conversion_Rate'] = df['Conversions'] / df['Impression'].replace(0, pd.NA) # Use pd.NA to get nullable float\n",
        "\n",
        "# 5. Select needed columns, including new ones (assumed to be non-campaign specific)\n",
        "df_subset = df[['Week_(Mon_to_Sun)', 'Region_(Matched)', 'Campaign_type',\n",
        "                'Impression', 'Conversions', 'Conversion_Rate', 'Cost',\n",
        "                'GQV', 'Population', 'Impression_share', 'Revenue']]\n",
        "\n",
        "# 6. Create a pivot table for campaign-type metrics\n",
        "# Use .stack() and .unstack() pattern for more control and handling missing combinations\n",
        "# Group by Week and Region first, then pivot Campaign_type\n",
        "pivot_table_processed = df_subset.groupby(['Week_(Mon_to_Sun)', 'Region_(Matched)', 'Campaign_type'])[\n",
        "    ['Impression', 'Conversions', 'Conversion_Rate', 'Cost']\n",
        "].sum().unstack(fill_value=0) # Use fill_value=0 for unstacking to handle missing campaign types\n",
        "\n",
        "# Flatten the column names\n",
        "pivot_table_processed.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_table_processed.columns]\n",
        "\n",
        "# 6b. Aggregate non-campaign-specific columns separately\n",
        "# Note: GQV and Impression_share are assumed to be non-campaign specific and aggregated here\n",
        "extras = df_subset.groupby(['Week_(Mon_to_Sun)', 'Region_(Matched)'])[\n",
        "    ['GQV', 'Population', 'Impression_share', 'Revenue']\n",
        "].sum() # Stay grouped for easier merge later\n",
        "\n",
        "total_conversions = df_subset.groupby(['Week_(Mon_to_Sun)', 'Region_(Matched)'])[ 'Conversions' ].sum().rename('Total_Conversions') # Stay grouped and rename\n",
        "\n",
        "# Combine processed pivot table and extras\n",
        "combined_df = pivot_table_processed.join([extras, total_conversions], how='left')\n",
        "\n",
        "# 7. Reset index to turn grouped columns into regular columns\n",
        "combined_df = combined_df.reset_index()\n",
        "combined_df = combined_df.rename(columns={'Week_(Mon_to_Sun)': 'Week'})\n",
        "\n",
        "# 8. Ensure complete time series and region combinations\n",
        "\n",
        "# Get all unique regions\n",
        "all_regions = combined_df['Region_(Matched)'].unique()\n",
        "\n",
        "# Get the min and max dates to create a full date range\n",
        "min_date = combined_df['Week'].min()\n",
        "max_date = combined_df['Week'].max()\n",
        "\n",
        "# Create a complete weekly date range\n",
        "# Assuming the data is weekly, start from the first Monday/Sunday and end on the last\n",
        "full_date_range = pd.date_range(start=min_date, end=max_date, freq='W-MON') # Assuming weekly data starts on Monday\n",
        "\n",
        "# Create a complete grid of all week and region combinations\n",
        "full_grid = pd.MultiIndex.from_product([full_date_range, all_regions], names=['Week', 'Region_(Matched)']).to_frame(index=False)\n",
        "\n",
        "# Merge the combined data onto the full grid\n",
        "# Use a left merge to keep all combinations from the full_grid\n",
        "pivot_table = full_grid.merge(combined_df, on=['Week', 'Region_(Matched)'], how='left')\n",
        "\n",
        "# 9. Fill NaN values after ensuring all week/region combinations exist\n",
        "# Define columns that should be filled with 0\n",
        "zero_fill_columns = [col for col in pivot_table.columns if any(metric in col for metric in ['Impression', 'Cost', 'Conversions'])] + ['GQV', 'Impression_share', 'Revenue', 'Total_Conversions', 'Population'] # Include other columns that should be 0 if missing\n",
        "\n",
        "for col in zero_fill_columns:\n",
        "    if col in pivot_table.columns:\n",
        "        pivot_table[col] = pivot_table[col].fillna(0)\n",
        "\n",
        "# Conversion Rate needs special handling - fill with 0 where Impressions are 0, else NaN can remain or be filled carefully\n",
        "# Recompute Conversion Rate where Impression is 0 after filling impressions with 0\n",
        "for campaign in df[\"Campaign_type\"].unique():\n",
        "    imp_col = f\"{campaign}_Impression\"\n",
        "    cr_col = f\"{campaign}_Conversion_Rate\"\n",
        "    if imp_col in pivot_table.columns and cr_col in pivot_table.columns:\n",
        "        # Recalculate CR where it might have been NaN initially due to 0 impressions before fillna\n",
        "        pivot_table[cr_col] = pivot_table[cr_col].fillna(\n",
        "            pivot_table[cr_col].where(pivot_table[imp_col] != 0, 0)\n",
        "        )\n",
        "        pivot_table[cr_col] = pivot_table[cr_col].fillna(0) # Fill any remaining NaNs\n",
        "\n",
        "# Convert 'Week' back to string format expected by Meridian if necessary, after ensuring regularity\n",
        "pivot_table['Week'] = pivot_table['Week'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "# 10. Final reorder\n",
        "# Identify columns dynamically\n",
        "all_cols = pivot_table.columns.tolist()\n",
        "fixed_cols = ['Week', 'Region_(Matched)']\n",
        "dynamic_cols = sorted([col for col in all_cols if col not in fixed_cols and col != 'Total_Conversions'])\n",
        "\n",
        "ordered_columns = fixed_cols + dynamic_cols + ['Total_Conversions']\n",
        "\n",
        "# Ensure all ordered columns are actually in the dataframe before reordering\n",
        "ordered_columns = [col for col in ordered_columns if col in pivot_table.columns]\n",
        "pivot_table = pivot_table[ordered_columns]\n",
        "\n",
        "\n",
        "# 11. Preview\n",
        "print(pivot_table.head())\n",
        "print(pivot_table['Week'].nunique(), \"unique weeks\")\n",
        "print(pivot_table['Region_(Matched)'].nunique(), \"unique regions\")\n",
        "print(pivot_table.shape, \"rows, columns\")\n",
        "\n",
        "# 12. Save to CSV\n",
        "output_path = '/content/drive/MyDrive/cleaned_meridian.csv'\n",
        "pivot_table.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "S_xS5XKdPf1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uc9f24qtP0lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JBDZzl80BrY"
      },
      "source": [
        "2\\. Map the media variables and the media spends to the designated channel names intended for display in the two-page HTML output. In the following example,  'Channel0_impression' and 'Channel0_spend' are connected to the same channel, 'Channel0'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qdTSk4a0znn"
      },
      "outputs": [],
      "source": [
        "coord_to_columns = load.CoordToColumns(\n",
        "    time='Week',\n",
        "    geo='Region_(Matched)',\n",
        "    controls=['GQV', 'Impression_share'],\n",
        "    population='Population',\n",
        "    kpi='Total_Conversions',\n",
        "    revenue_per_kpi='Revenue',\n",
        "    media=[\n",
        "        'Search_Impression',\n",
        "        'PMAX_Impression',\n",
        "        'Display_Impression',\n",
        "        'DemandGen_Impression'\n",
        "    ],\n",
        "    media_spend=[\n",
        "        'Search_Cost',\n",
        "        'PMAX_Cost',\n",
        "        'Display_Cost',\n",
        "        'DemandGen_Cost'\n",
        "    ]\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_media_to_channel = {\n",
        " 'Search_Impression': 'Search',\n",
        "    'PMAX_Impression': 'Performance_Max',\n",
        "    'Display_Impression': 'Display',\n",
        "    'DemandGen_Impression': 'Demand_Gen',\n",
        "}\n",
        "correct_media_spend_to_channel = {\n",
        "    'Search_Cost': 'Search',\n",
        "    'PMAX_Cost': 'Performance_Max',\n",
        "    'Display_Cost': 'Display',\n",
        "    'DemandGen_Cost': 'Demand_Gen',\n",
        "}"
      ],
      "metadata": {
        "id": "bLzbY6EQP2_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNr75vQL1Zru"
      },
      "source": [
        "3\\. Load the CSV data using `CsvDataLoader`. Note that `csv_path` is the path to the data file location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udaLGvwl1U8B"
      },
      "outputs": [],
      "source": [
        "loader = load.CsvDataLoader(\n",
        "    csv_path='/content/drive/MyDrive/cleaned_meridian.csv',\n",
        "    kpi_type='non_revenue',\n",
        "    coord_to_columns=coord_to_columns,\n",
        "    media_to_channel=correct_media_to_channel,\n",
        "    media_spend_to_channel=correct_media_spend_to_channel,\n",
        ")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlF5vs8vb8Wn"
      },
      "source": [
        "Note that the simulated data here contains reach and frequency channels. We recommend including reach and frequency data whenever they are available. For information about the advantages of utilizing reach and frequency, see [Bayesian Hierarchical Media Mix Model Incorporating Reach and Frequency Data](https://research.google/pubs/bayesian-hierarchical-media-mix-model-incorporating-reach-and-frequency-data/#:~:text=By%20incorporating%20R%26F%20into%20MMM,based%20on%20optimal%20frequency%20recommendations.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO6pDd6f2V1L"
      },
      "source": [
        "<a name=\"configure-model\"></a>\n",
        "## Step 2: Configure the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_mQI7HzxxK4"
      },
      "source": [
        "Meridian uses Bayesian framework and Markov Chain Monte Carlo (MCMC) algorithms to sample from the posterior distribution.\n",
        "\n",
        "1\\. Inititalize the `Meridian` class by passing the loaded data and the customized model specification. One advantage of Meridian lies in its capacity to calibrate the model directly through ROI priors, as described in [Media Mix Model Calibration With Bayesian Priors](https://research.google/pubs/media-mix-model-calibration-with-bayesian-priors/). In this particular example, the ROI priors for all media channels are identical, with each being represented as Lognormal(0.2, 0.9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XNDd7HX1qTn"
      },
      "outputs": [],
      "source": [
        "roi_rf_mu = 0.2     # Mu for ROI prior for each RF channel.\n",
        "roi_rf_sigma = 0.9  # Sigma for ROI prior for each RF channel.\n",
        "prior = prior_distribution.PriorDistribution(\n",
        "    roi_rf=tfp.distributions.LogNormal(roi_rf_mu, roi_rf_sigma, name=constants.ROI_RF)\n",
        ")\n",
        "model_spec = spec.ModelSpec(prior=prior)\n",
        "\n",
        "mmm = model.Meridian(input_data=data, model_spec=model_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPQBPlX8cmEv"
      },
      "source": [
        "2\\. Use the `sample_prior()` and `sample_posterior()` methods to obtain samples from the prior and posterior distributions of model parameters. If you are using the T4 GPU runtime this step may take about 10 minutes for the provided data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVB3avRdcRNz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "mmm.sample_prior(500)\n",
        "mmm.sample_posterior(n_chains=10, n_adapt=2000, n_burnin=500, n_keep=500, seed=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WUM2V26cspo"
      },
      "source": [
        "For more information about configuring the parameters and using a customized model specification, such as setting different ROI priors for each media channel, see [Configure the model](https://developers.google.com/meridian/docs/user-guide/configure-model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9oECJwUdJTm"
      },
      "source": [
        "<a name=\"model-diagnostics\"></a>\n",
        "## Step 3: Run model diagnostics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSzK6JeMxrV6"
      },
      "source": [
        "After the model is built, you must assess convergence, debug the model if needed, and then assess the model fit.\n",
        "\n",
        "1\\. Assess convergence. Run the following code to generate r-hat statistics. R-hat close to 1.0 indicate convergence. R-hat < 1.2 indicates approximate convergence and is a reasonable threshold for many problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFuc7B86yLvM"
      },
      "outputs": [],
      "source": [
        "model_diagnostics = visualizer.ModelDiagnostics(mmm)\n",
        "model_diagnostics.plot_rhat_boxplot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCwt5SGYxlaE"
      },
      "source": [
        "2\\. Assess the model's fit by comparing the expected sales against the actual sales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z4zJtHyyhif"
      },
      "outputs": [],
      "source": [
        "model_fit = visualizer.ModelFit(mmm)\n",
        "model_fit.plot_model_fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76IBQcWLu980"
      },
      "source": [
        "For more information and additional model diagnostics checks, see [Modeling diagnostics](https://developers.google.com/meridian/docs/user-guide/model-diagnostics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGUOFFbCdOtl"
      },
      "source": [
        "<a name=\"generate-summary\"></a>\n",
        "## Step 4: Generate model results & two-page output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puHjkyvZEOEg"
      },
      "source": [
        "To export the two-page HTML summary output, initialize the `Summarizer` class with the model object. Then pass in the filename, filepath, start date, and end date to `output_model_results_summary` to run the summary for that time duration and save it to the specified file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keOpq1qKNbq0"
      },
      "outputs": [],
      "source": [
        "mmm_summarizer = summarizer.Summarizer(mmm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltr4uP80YQe7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbgNaDYpIfQl"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/drive/MyDrive'\n",
        "start_date = '2021-01-25'\n",
        "end_date = '2024-01-15'\n",
        "mmm_summarizer.output_model_results_summary('summary_output.html', filepath, start_date, end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9sBxuvidmr8"
      },
      "source": [
        "Here is a preview of the two-page output based on the simulated data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaUe7uZRfJPm"
      },
      "outputs": [],
      "source": [
        "IPython.display.HTML(filename='/content/drive/MyDrive/summary_output.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PphWMfKdwPIw"
      },
      "source": [
        "For a customized two-page report, model results summary table, and individual visualizations, see [Model results report](https://developers.google.com/meridian/docs/user-guide/generate-model-results-report) and [plot media visualizations](https://developers.google.com/meridian/docs/user-guide/plot-media-visualizations).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msqwz2MN5mTq"
      },
      "source": [
        "<a name=\"generate-optimize\"></a>\n",
        "## Step 5: Run budget optimization & generate an optimization report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khCL6Q2sS-iy"
      },
      "source": [
        "You can choose what scenario to run for the budget allocation. In default scenario, you find the optimal allocation across channels for a given budget to maximize the return on investment (ROI).\n",
        "\n",
        "1\\. Instantiate the `BudgetOptimizer` class and run the `optimize()` method without any customization, to run the default library's Fixed Budget Scenario to maximize ROI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38lhqyLvHf51"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "budget_optimizer = optimizer.BudgetOptimizer(mmm)\n",
        "optimization_results = budget_optimizer.optimize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLOMqDmCRKRO"
      },
      "source": [
        "2\\. Export the 2-page HTML optimization report, which contains optimized spend allocations and ROI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at7V7YEh_zwZ"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/drive/MyDrive'\n",
        "optimization_results.output_optimization_summary('optimization_output.html', filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq_mcrj1STDU"
      },
      "outputs": [],
      "source": [
        "IPython.display.HTML(filename='/content/drive/MyDrive/optimization_output.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIWTubaN0RKC"
      },
      "source": [
        "For information about customized optimization scenarios, such as flexible budget scenarios, see [Budget optimization scenarios](https://developers.google.com/meridian/docs/user-guide/budget-optimization-scenarios). For more information about optimization results summary and individual visualizations, see [optimization results output](https://developers.google.com/meridian/docs/user-guide/generate-optimization-results-output) and [optimization visualizations](https://developers.google.com/meridian/docs/user-guide/plot-optimization-visualizations)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m98O3a_TrVg"
      },
      "source": [
        "<a name=\"save-model\"></a>\n",
        "## Step 6: Save the model object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zjh64YG8Dti"
      },
      "source": [
        "We recommend that you save the model object for future use. This helps you to  avoid repetitive model runs and saves time and computational resources. After the model object is saved, you can load it at a later stage to continue the analysis or visualizations without having to re-run the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kamZpyv8KMh"
      },
      "source": [
        "Run the following codes to save the model object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfaQQ8-fTw0K"
      },
      "outputs": [],
      "source": [
        "file_path='/content/drive/MyDrive/saved_mmm.pkl'\n",
        "model.save_mmm(mmm, file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2v_s2uS8PgA"
      },
      "source": [
        "Run the following codes to load the saved model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGUmiYI48epA"
      },
      "outputs": [],
      "source": [
        "mmm = model.load_mmm(file_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}